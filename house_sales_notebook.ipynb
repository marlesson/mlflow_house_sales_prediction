{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![house Logo](https://www.imovelweb.com.br/noticias/wp-content/uploads/2013/08/venda2.jpg)\n",
    "\n",
    "# House Sales in King County, USA\n",
    "\n",
    "\n",
    "Este conjunto de dados contém preços de imóveis para o Condado de King, que inclui Seattle. Inclui casas vendidas entre maio de 2014 e maio de 2015.\n",
    "\n",
    "https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "py.init_notebook_mode(connected=True)\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "df  = pd.read_csv('data/raw.csv', parse_dates=['date'], index_col=['id'])#.set_index('date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "df_plot = df.set_index('date').resample('W').count()['price'].reset_index()\n",
    "trace1  = go.Scatter(x=df_plot.date, y=df_plot.price)\n",
    "data    = [trace1]\n",
    "layout = go.Layout(\n",
    "    title='Total de casas vendidas por semana',\n",
    "    xaxis=dict(title='Data'),\n",
    "    yaxis=dict(title='Total')\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema\n",
    "\n",
    "\n",
    "**Devemos criar um modelo para prever o preço do imóvel a partir de alguns dados, esse modelo será utilizado em um portal de classificados de imóveis**\n",
    "\n",
    "![house Logo](https://i.imgur.com/Wf7316S.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Dados\n",
    "\n",
    "* Engenharia de Features\n",
    "* Transformações \n",
    "* Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(2).to_json(orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['bedrooms_per_sqft_living'] = df.bedrooms/df.sqft_living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sample\n",
    "df.drop([\"date\",\"price\"], axis=1).sample(10)\\\n",
    "    .to_csv('data/predict_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Avaliação\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae  = mean_absolute_error(actual, pred)\n",
    "    r2   = r2_score(actual, pred)\n",
    "    return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataset\n",
    "df.to_csv('artefacts/dataset.csv', index=False)\n",
    "\n",
    "# Features\n",
    "X = df.drop([\"date\",\"price\"], axis=1)\n",
    "\n",
    "# Target\n",
    "y = df['price']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, \\\n",
    "     y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Features\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# target\n",
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define Model\n",
    "params = {'fit_intercept': False, 'normalize': True, 'n_jobs': -1}\n",
    "\n",
    "model  = LinearRegression(**params)\n",
    "\n",
    "#train\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "pred_y = model.predict(X_test)\n",
    "\n",
    "(rmse, mae, r2) = eval_metrics(y_test, pred_y)\n",
    "\n",
    "print(\"RMSE: %s\" % rmse)\n",
    "print(\"MAE: %s\" % mae)\n",
    "print(\"R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "g = sns.jointplot(x=y_test, y=pred_y, kind=\"reg\", color=\"m\", height=7)\n",
    "g.savefig('artefacts/img_res_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# # traking\n",
    "\n",
    "# # log in ml FLow\n",
    "# with mlflow.start_run():\n",
    "    \n",
    "#     # SAlva pasta de artefatos\n",
    "#     mlflow.log_artifacts(\"artefacts/\")\n",
    "    \n",
    "#     # Salva parametros\n",
    "#     for k, v in params.items():\n",
    "#         mlflow.log_param(k, v)\n",
    "    \n",
    "#     # Salva métricas\n",
    "#     mlflow.log_metric(\"RMSE\", rmse)\n",
    "#     mlflow.log_metric(\"MAE\",  mae)\n",
    "#     mlflow.log_metric(\"R2\",   r2)\n",
    "    \n",
    "#     # salva model\n",
    "#     mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define Model\n",
    "params = {'n_estimators': 10, \n",
    "          'max_depth': 10, \n",
    "          'n_jobs': -1}\n",
    "\n",
    "model  = RandomForestRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "pred_y = model.predict(X_test)\n",
    "(rmse, mae, r2) = eval_metrics(y_test, pred_y)\n",
    "\n",
    "print(\"RMSE: %s\" % rmse)\n",
    "print(\"MAE: %s\" % mae)\n",
    "print(\"R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.jointplot(x=y_test, y=pred_y, kind=\"reg\", color=\"m\", height=7)\n",
    "g.savefig('artefacts/img_res_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# # tracking\n",
    "# with mlflow.start_run():\n",
    "    \n",
    "#     mlflow.log_artifacts(\"artefacts/\")\n",
    "    \n",
    "#     for k, v in params.items():\n",
    "#         mlflow.log_param(k, v)\n",
    "        \n",
    "#     mlflow.log_metric(\"RMSE\", rmse)\n",
    "#     mlflow.log_metric(\"MAE\",  mae)\n",
    "#     mlflow.log_metric(\"R2\",   r2)\n",
    "    \n",
    "#     mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline de ML\n",
    "\n",
    "![image.png](https://i.imgur.com/Scx9nFd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "joblib.dump(model, './artefacts/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "model = joblib.load('./artefacts/model.pkl')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X_test.sample(1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow\n",
    "\n",
    "![mlflow](https://databricks.com/wp-content/uploads/2018/06/mlflow.png)\n",
    "\n",
    "https://mlflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste Simples do Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "#mlflow.set_tracking_uri(\"http://34.73.179.244/\")\n",
    "\n",
    "# log in ml FLow\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.log_artifacts(\"artefacts/\")\n",
    "    \n",
    "    mlflow.log_param(\"param1\", 0)\n",
    "    \n",
    "    mlflow.log_metric(\"RMSE\", 0)\n",
    "    mlflow.log_metric(\"MAE\",  0)\n",
    "    mlflow.log_metric(\"R2\",   0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential([\n",
    "    Dense(100, input_shape=(X_train.shape[1],)),\n",
    "    Activation('relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "hist = model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test), \n",
    "          batch_size=254, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    # summarize history for loss\n",
    "    fig, ax = plt.subplots()  # create figure & 1 axis\n",
    "\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    return fig \n",
    "\n",
    "fig = plot_hist(hist)\n",
    "fig.savefig('artefacts/train_hist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "pred_y = model.predict(X_test).reshape(-1)\n",
    "(rmse, mae, r2) = eval_metrics(y_test, pred_y)\n",
    "\n",
    "print(\"RMSE: %s\" % rmse)\n",
    "print(\"MAE: %s\" % mae)\n",
    "print(\"R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "g = sns.jointplot(x=y_test, y=pred_y, kind=\"reg\", color=\"m\", height=7)\n",
    "g.savefig('artefacts/img_res_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import keras\n",
    "\n",
    "# log in ml FLow\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.log_artifacts(\"artefacts/\")\n",
    "    \n",
    "    mlflow.log_param('layers', [32])\n",
    "    \n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"MAE\",  mae)\n",
    "    mlflow.log_metric(\"R2\",   r2)\n",
    "    \n",
    "    mlflow.keras.log_model(model, \"model\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
